"""
üß™ Test Fix gen_long: Prompt adapt√© pour explications d√©taill√©es
"""

import asyncio
import yaml
from pathlib import Path
import sys

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from intelligence.neural_pathway_manager import NeuralPathwayManager
from intelligence.core import process_llm_request


def load_config():
    with open('config/config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


async def test_gen_long_fix():
    print("=" * 70)
    print("üß™ TEST FIX GEN_LONG: Prompt adapt√© pour explications")
    print("=" * 70 + "\n")
    
    config = load_config()
    llm_handler = NeuralPathwayManager(config)
    print("‚úÖ LLM handler initialized\n")
    
    # Test question qui n√©cessite explication
    question = "explique moi la causalit√©"
    
    print(f"üì¢ Question: {question}")
    print("üéØ Classification attendue: gen_long")
    print("üìù Prompt adapt√©: 2-4 phrases autoris√©es\n")
    
    response = await process_llm_request(
        llm_handler=llm_handler,
        prompt=question,
        context="mention",
        user_name="el_serda_test",
        game_cache=None,
    )
    
    print(f"ü§ñ R√©ponse: {response}")
    print(f"üìè Longueur: {len(response)} caract√®res")
    
    # Compter les phrases
    phrase_count = response.count('.') + response.count('!') + response.count('?')
    print(f"üìä Phrases d√©tect√©es: ~{phrase_count}")
    
    if phrase_count >= 2:
        print("‚úÖ Explication d√©taill√©e g√©n√©r√©e (‚â•2 phrases)")
    else:
        print("‚ö†Ô∏è R√©ponse trop courte pour gen_long")
    
    print("\n" + "=" * 70)
    print("‚úÖ TEST TERMIN√â")
    print("=" * 70)


if __name__ == "__main__":
    asyncio.run(test_gen_long_fix())
