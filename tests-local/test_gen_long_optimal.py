"""
ğŸ§ª Test Optimal gen_long: Matrice complÃ¨te prompt Ã— max_tokens

Teste TOUTES les combinaisons pour trouver l'Ã©quilibre parfait:
- Partie 1: Prompts variables (1/2/3 phrases) avec max_tokens FIXE
- Partie 2: Max_tokens variables avec prompts FIXES (1/2/3 phrases)
- Objectif: â‰¤400 chars, pas de troncature, explications claires
"""

import asyncio
import yaml
from pathlib import Path
import sys

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from intelligence.synapses.local_synapse import LocalSynapse


def load_config():
    with open('config/config.yaml', 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


async def test_combination(synapse, question, prompt_phrases, max_tokens, test_num, total):
    """Test une combinaison spÃ©cifique"""
    print(f"\n{'='*70}")
    print(f"ğŸ§ª TEST {test_num}/{total}: {prompt_phrases} phrase(s) | max_tokens={max_tokens}")
    print(f"{'='*70}")
    
    # Construire le prompt adaptÃ©
    bot_name = "serda_bot"
    personality = synapse.config.get("bot", {}).get("personality", "")
    
    if prompt_phrases == 1:
        system_prompt = (
            f"Tu es {bot_name}. {personality}\n"
            f"RÃ©ponds en 1 PHRASE CLAIRE EN FRANÃ‡AIS, SANS TE PRÃ‰SENTER.\n"
            f"DÃ©finition + exemple concret.\n"
            f"Utilise des emojis (ğŸ’¡ğŸ”„ğŸ¯).\n"
            f"Question: {question}\n"
            f"RÃ©ponse:"
        )
    elif prompt_phrases == 2:
        system_prompt = (
            f"Tu es {bot_name}. {personality}\n"
            f"RÃ©ponds en 2 PHRASES CLAIRES EN FRANÃ‡AIS, SANS TE PRÃ‰SENTER.\n"
            f"1. DÃ©finition simple + exemple\n"
            f"2. Cas d'usage ou approfondissement\n"
            f"Utilise des emojis (ğŸ’¡ğŸ”„ğŸ¯).\n"
            f"Question: {question}\n"
            f"RÃ©ponse:"
        )
    else:  # 3 phrases
        system_prompt = (
            f"Tu es {bot_name}. {personality}\n"
            f"RÃ©ponds en 3 PHRASES CLAIRES EN FRANÃ‡AIS, SANS TE PRÃ‰SENTER.\n"
            f"1. DÃ©finition simple\n"
            f"2. Exemple concret\n"
            f"3. Cas d'usage pratique\n"
            f"Utilise des emojis (ğŸ’¡ğŸ”„ğŸ¯).\n"
            f"Question: {question}\n"
            f"RÃ©ponse:"
        )
    
    messages = [{"role": "user", "content": system_prompt}]
    
    # Appel direct avec max_tokens custom
    try:
        # Simuler l'appel _transmit_local_signal avec max_tokens custom
        import httpx
        
        payload = {
            "model": synapse.model_name,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": 0.7,
            "stream": True,
        }
        
        full_response = ""
        async with httpx.AsyncClient(timeout=httpx.Timeout(20.0)) as client:
            async with client.stream("POST", synapse.endpoint, json=payload) as response:
                if response.status_code != 200:
                    print(f"âŒ Erreur HTTP {response.status_code}")
                    return None
                
                async for line in response.aiter_lines():
                    if not line.startswith("data: "):
                        continue
                    
                    chunk_data = line[6:]
                    if chunk_data == "[DONE]":
                        break
                    
                    try:
                        import json
                        chunk_json = json.loads(chunk_data)
                        delta = chunk_json.get("choices", [{}])[0].get("delta", {})
                        content = delta.get("content", "")
                        if content:
                            full_response += content
                    except:
                        continue
        
        response = full_response.strip()
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None
    
    if not response:
        print("âŒ Pas de rÃ©ponse gÃ©nÃ©rÃ©e")
        return None
    
    length = len(response)
    phrase_count = response.count('.') + response.count('!') + response.count('?')
    is_truncated = response.endswith('...') or length >= max_tokens * 3  # Approximation
    
    print(f"ğŸ“ Longueur: {length} caractÃ¨res")
    print(f"ğŸ“Š Phrases: ~{phrase_count}")
    print(f"âœ‚ï¸ TronquÃ©: {'OUI âŒ' if is_truncated else 'NON âœ…'}")
    print(f"ğŸ“ Limite 400: {'OK âœ…' if length <= 400 else f'DÃ‰PASSÃ‰ âŒ (+{length-400})'}")
    
    # Afficher la rÃ©ponse complÃ¨te
    print(f"\nğŸ“ RÃ©ponse complÃ¨te:")
    print(f"   {response}")
    
    # Score de qualitÃ©
    score = 0
    if not is_truncated:
        score += 50  # Pas de troncature = crucial
    if length <= 400:
        score += 30  # Respecte la limite
    else:
        score -= (length - 400) // 10  # PÃ©nalitÃ© si dÃ©passement
    if phrase_count == prompt_phrases:
        score += 15  # Respecte le nombre de phrases demandÃ©
    elif abs(phrase_count - prompt_phrases) == 1:
        score += 10  # Proche du nombre demandÃ©
    if 150 <= length <= 400:
        score += 5  # Bon Ã©quilibre longueur
    
    score = max(0, min(100, score))  # Clamp 0-100
    
    print(f"\nâ­ Score qualitÃ©: {score}/100")
    
    await asyncio.sleep(0.5)  # Ã‰viter spam LM Studio
    
    return {
        "prompt_phrases": prompt_phrases,
        "max_tokens": max_tokens,
        "length": length,
        "phrases": phrase_count,
        "truncated": is_truncated,
        "score": score,
        "response": response
    }


async def run_full_matrix_test():
    print("=" * 70)
    print("ğŸ¯ TEST MATRICE COMPLÃˆTE: Prompt Ã— max_tokens")
    print("Objectifs:")
    print("  - â‰¤400 caractÃ¨res (Twitch confortable)")
    print("  - Pas de troncature")
    print("  - Nombre de phrases respectÃ©")
    print("=" * 70)
    
    config = load_config()
    synapse = LocalSynapse(config)
    print("âœ… LocalSynapse initialized\n")
    
    # Questions variÃ©es pour tester robustesse
    questions = [
        "explique moi la causalitÃ©",
        "c'est quoi la mÃ©canique quantique",
        "comment fonctionne la gravitÃ©",
        "qu'est ce que l'entropie",
        "explique moi la relativitÃ©",
    ]
    
    print(f"ğŸ“¢ Questions test ({len(questions)} variantes):")
    for q in questions:
        print(f"   â€¢ {q}")
    print()
    
    results = []
    
    # ============================================
    # PARTIE 1: Prompts variables, max_tokens FIXE
    # ============================================
    print("\n" + "ğŸ”¸" * 35)
    print("ğŸ“Š PARTIE 1: PROMPTS VARIABLES (max_tokens=250 fixe)")
    print("ğŸ”¸" * 35)
    
    fixed_max_tokens = 250
    test_num = 0
    total_tests = len(questions) * 9  # 5 questions Ã— 9 configs
    
    for question in questions:
        print(f"\n{'â”€' * 70}")
        print(f"ğŸ“ Question: '{question}'")
        print(f"{'â”€' * 70}")
        
        for phrases in [1, 2, 3]:
            test_num += 1
            result = await test_combination(synapse, question, phrases, fixed_max_tokens, test_num, total_tests)
            if result:
                result['question'] = question
                results.append(result)
    
    # ============================================
    # PARTIE 2: max_tokens variables, prompts FIXES
    # ============================================
    print("\n" + "ğŸ”¹" * 35)
    print("ğŸ“Š PARTIE 2: MAX_TOKENS VARIABLES")
    print("ğŸ”¹" * 35)
    
    # Test 2.1: 1 phrase, max_tokens variables
    for question in questions:
        print(f"\n{'â”€' * 70}")
        print(f"ğŸ“ Question: '{question}'")
        print(f"{'â”€' * 70}")
        print("\n--- 1 PHRASE, max_tokens variables ---")
        
        for tokens in [150, 200, 250]:
            test_num += 1
            result = await test_combination(synapse, question, 1, tokens, test_num, total_tests)
            if result:
                result['question'] = question
                results.append(result)
    
    # Test 2.2: 2 phrases, max_tokens variables
    for question in questions:
        print(f"\n{'â”€' * 70}")
        print(f"ğŸ“ Question: '{question}'")
        print(f"{'â”€' * 70}")
        print("\n--- 2 PHRASES, max_tokens variables ---")
        
        for tokens in [200, 250, 300]:
            test_num += 1
            result = await test_combination(synapse, question, 2, tokens, test_num, total_tests)
            if result:
                result['question'] = question
                results.append(result)
    
    # Analyse finale
    print("\n" + "=" * 70)
    print("ğŸ“Š ANALYSE FINALE - TOUS LES RÃ‰SULTATS")
    print("=" * 70)
    
    if results:
        # Statistiques globales
        total_tests = len(results)
        avg_score = sum(r['score'] for r in results) / total_tests
        avg_length = sum(r['length'] for r in results) / total_tests
        truncated_count = sum(1 for r in results if r['truncated'])
        over_400_count = sum(1 for r in results if r['length'] > 400)
        
        print(f"\nğŸ“ˆ STATISTIQUES GLOBALES ({total_tests} tests):")
        print(f"   â€¢ Score moyen: {avg_score:.1f}/100")
        print(f"   â€¢ Longueur moyenne: {avg_length:.0f} caractÃ¨res")
        print(f"   â€¢ TronquÃ©s: {truncated_count}/{total_tests} ({truncated_count/total_tests*100:.1f}%)")
        print(f"   â€¢ >400 chars: {over_400_count}/{total_tests} ({over_400_count/total_tests*100:.1f}%)")
        
        # Trier par score
        results.sort(key=lambda x: x['score'], reverse=True)
        
        print("\nğŸ† TOP 5 CONFIGURATIONS TOUTES QUESTIONS CONFONDUES:")
        for i, r in enumerate(results[:5], 1):
            print(f"\n{i}. Score: {r['score']}/100")
            print(f"   - Question: '{r['question']}'")
            print(f"   - Prompt: {r['prompt_phrases']} phrase(s)")
            print(f"   - max_tokens: {r['max_tokens']}")
            print(f"   - Longueur: {r['length']} chars")
            print(f"   - Phrases rÃ©elles: {r['phrases']}")
            print(f"   - TronquÃ©: {'OUI âŒ' if r['truncated'] else 'NON âœ…'}")
        
        # Analyse par configuration (agrÃ©gation)
        print("\nğŸ“Š PERFORMANCE PAR CONFIGURATION:")
        config_stats = {}
        for r in results:
            key = (r['prompt_phrases'], r['max_tokens'])
            if key not in config_stats:
                config_stats[key] = []
            config_stats[key].append(r['score'])
        
        config_avg = [(k, sum(v)/len(v), len(v)) for k, v in config_stats.items()]
        config_avg.sort(key=lambda x: x[1], reverse=True)
        
        print("\nğŸ¯ TOP 3 CONFIGS (moyenne sur toutes questions):")
        for i, (config, avg, count) in enumerate(config_avg[:3], 1):
            phrases, tokens = config
            print(f"{i}. {phrases} phrase(s) + max_tokens={tokens}")
            print(f"   â†’ Score moyen: {avg:.1f}/100 (sur {count} tests)")
        
        best_config = config_avg[0][0]
        print(f"\nğŸ’¡ CONFIGURATION OPTIMALE RECOMMANDÃ‰E:")
        print(f"   Prompt: {best_config[0]} phrase(s) claires")
        print(f"   max_tokens: {best_config[1]}")
        print(f"   Robustesse: TestÃ© sur {len(questions)} questions variÃ©es")
        print(f"   Score moyen: {config_avg[0][1]:.1f}/100")
        
        # Exemple de meilleure rÃ©ponse
        best_result = results[0]
        print(f"\nğŸ“ MEILLEURE RÃ‰PONSE (score {best_result['score']}/100):")
        print(f"   Question: '{best_result['question']}'")
        preview = best_result['response'][:300] + "..." if len(best_result['response']) > 300 else best_result['response']
        print(f"   RÃ©ponse: {preview}")
    
    print("\n" + "=" * 70)
    print("âœ… TEST MATRICE TERMINÃ‰")
    print("=" * 70)


if __name__ == "__main__":
    asyncio.run(run_full_matrix_test())

