"""
üé¨ Test DEBUG: Affichage streaming en temps r√©el
Visualiser les chunks arriver progressivement (GPU brid√© = + chunks)
"""

import asyncio
import yaml


async def test_streaming_visual_debug():
    """Test avec debug_streaming=True pour voir les chunks en temps r√©el"""
    print("=" * 60)
    print("üé¨ TEST STREAMING VISUEL (DEBUG MODE)")
    print("=" * 60)
    print("\n‚ö†Ô∏è  GPU layers brid√© recommand√© pour voir plus de chunks\n")
    
    # Load config et ACTIVER debug_streaming
    with open("config/config.yaml") as f:
        config = yaml.safe_load(f)
    
    # üé¨ ACTIVER DEBUG STREAMING
    config['llm']['debug_streaming'] = True
    
    from intelligence.neural_pathway_manager import NeuralPathwayManager
    llm_handler = NeuralPathwayManager(config)
    
    print("üîß Config:")
    print(f"   Model: {llm_handler.local_synapse.model_name}")
    print(f"   Debug streaming: {llm_handler.local_synapse.debug_streaming}")
    print(f"   Endpoint: {llm_handler.local_synapse.endpoint}\n")
    
    # Test avec plusieurs prompts
    prompts = [
        ("Blague courte", "R√©ponds EN 1 PHRASE MAX EN FRAN√áAIS, SANS TE PR√âSENTER, style humoristique : raconte une blague courte"),
        ("Fact science", "R√©ponds EN 1 PHRASE MAX EN FRAN√áAIS, SANS TE PR√âSENTER : partage un fait scientifique fascinant"),
        ("Dev joke", "R√©ponds EN 1 PHRASE MAX EN FRAN√áAIS, SANS TE PR√âSENTER : raconte une blague sur les d√©veloppeurs"),
    ]
    
    for i, (title, prompt) in enumerate(prompts, 1):
        print(f"\n{'=' * 60}")
        print(f"üéØ TEST {i}/3: {title}")
        print(f"{'=' * 60}")
        print(f"üìù Prompt: {prompt[:50]}...\n")
        
        response = await llm_handler.local_synapse.fire(
            stimulus=prompt,
            context="direct",
            stimulus_class="gen_short",
            correlation_id=f"visual_test_{i}"
        )
        
        print(f"\n‚úÖ R√©ponse finale: {response}\n")
        
        if i < len(prompts):
            print("‚è∏Ô∏è  Pause 1s avant prochain test...")
            await asyncio.sleep(1)
    
    print("\n" + "=" * 60)
    print("‚úÖ TEST STREAMING VISUEL TERMIN√â !")
    print("=" * 60)
    print("\nüí° Remarques:")
    print("   - Chunks affich√©s en temps r√©el (progressive)")
    print("   - GPU brid√© = + chunks visibles")
    print("   - Accumulation = pas de spam chat")
    print("   - Message complet envoy√© √† stop_reason\n")


if __name__ == "__main__":
    print("\nüé¨ STREAMING DEBUG MODE ".center(60, "="))
    print("Voir les chunks LLM arriver en temps r√©el !\n")
    
    asyncio.run(test_streaming_visual_debug())
